{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Zones And Scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\carnd\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from lesson_functions_udacity import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zone_list = [((700,340),(1280,720),0.61,0.5),\n",
    "             ((700,370),(1220,530),0.63,0.8),\n",
    "             ((700,395),(1100,470),0.65,0.5)]\n",
    "             \n",
    "             \n",
    "scales = [[(160,160),(110,110)],\n",
    "          [(110,110),(75,75)],\n",
    "          [(75,75),(45,45)]]\n",
    "          \n",
    "\n",
    "n = 20\n",
    "t = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "vehicles = []\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        \n",
    "        # average over consecutive frames\n",
    "        if len(vehicles) == labels[1]:\n",
    "            vehicles[car_number-1].append(np.array(bbox))\n",
    "            if len(vehicles[car_number-1]) > 35:\n",
    "                del(vehicles[car_number-1][0])\n",
    "            bbox = np.int_(np.mean(np.array(vehicles[car_number-1]),axis = 0))     \n",
    "            bbox = tuple(map(tuple, bbox))\n",
    "        else:\n",
    "            if car_number == 1:\n",
    "                del(vehicles[:])\n",
    "            vehicles.append([np.array(bbox)])\n",
    "        \n",
    "        \n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 4)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_video(image):\n",
    "\n",
    "\n",
    "    all_windows = []\n",
    "    for zone, window_list in zip(zone_list,scales):\n",
    "        zone_windows = []\n",
    "        thresh = zone[-1]\n",
    "        overlap = zone[2]\n",
    "        for window in window_list:\n",
    "            windows = slide_window(image, x_start_stop=[zone[0][0], zone[1][0]], y_start_stop=[zone[0][1], zone[1][1]], \n",
    "                                   xy_window=window, xy_overlap=(overlap, overlap))\n",
    "            zone_windows.extend(windows)\n",
    "        all_windows.append([zone_windows,thresh])\n",
    "\n",
    "    all_windows = all_windows\n",
    "    \n",
    "    \n",
    "    svc = pickle.load(open( \"pickle/classifier.p\", \"rb\" ))\n",
    "    params = pickle.load(open( \"pickle/feature_params.p\", \"rb\" ))\n",
    "\n",
    "    \n",
    "    X_scaler = params['scaler']\n",
    "    color_space = params['color_space']\n",
    "    spatial_size = params['spatial_size']\n",
    "    hist_bins = params['hist_bins']\n",
    "    orient = params['orient']\n",
    "    pix_per_cell = params['pix_per_cell']\n",
    "    cell_per_block = params['cell_per_block']\n",
    "    hog_channel = params['hog_channel']\n",
    "    \n",
    "    hot_windows = []\n",
    "    \n",
    "    for zone_windows in all_windows:\n",
    "        thresh = zone_windows[-1]\n",
    "        hot_windows.append(search_windows(image, zone_windows[0], svc, X_scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=True, \n",
    "                                hist_feat=True, hog_feat=True, thresh = thresh))\n",
    "                           \n",
    "    box_list = []\n",
    "    for zone in hot_windows:\n",
    "        for box in zone:\n",
    "            box_list.append(box)\n",
    "    \n",
    "    \n",
    "    \n",
    "    frames.append(box_list)\n",
    "    \n",
    "    if len(frames) > n:\n",
    "        del(frames[0])\n",
    "    \n",
    "    box_list = []\n",
    "    for frame in frames:\n",
    "        box_list.extend(frame)\n",
    "    \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    draw_img = None\n",
    "    heatmap = None\n",
    "    \n",
    "    \n",
    "   \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,t)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    \n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    \n",
    "    \n",
    "    return draw_img\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video final_video2.mp4\n",
      "[MoviePy] Writing video final_video2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████▉| 1260/1261 [1:10:01<00:04,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: final_video2.mp4 \n",
      "\n",
      "Wall time: 1h 10min 4s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "white_output = 'final_video2.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(40,43)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_video) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"final_video2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
